# This is the config file for the simple train
# It uses a tokenizer that's just the vocab of the shakespeare dataset
checkpoint_dir = './checkpoints/mini'
dataset = 'mini'
tokenizer = 'mini'

vocab_size = 65  # this is for shakespeare homemade encoder. Could calculate it

# At the moment they use the same hyperparameters, but this may change
hyperparameters = 'hyperparameters.toml'
